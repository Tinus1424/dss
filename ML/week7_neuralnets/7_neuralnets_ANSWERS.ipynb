{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will start with a simple toy implementation of a neural network and apply it to the XOR problem. In the second part we will learn how to use the [Pytorch toolkit](https://pytorch.org/) to define, train and use a practical neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR\n",
    "\n",
    "Let's start with the [XOR problem](https://en.wikipedia.org/wiki/XOR_gate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1\n",
    "Define the function `xor`, which which takes a Nx2 array, where each row is an input to the logical XOR. It outputs an array of size N with the corresponding outputs.\n",
    "\n",
    "Given `X = numpy.array([[0, 0],      \n",
    "                 [0, 1],      \n",
    "                 [1, 0],      \n",
    "                 [1, 1]])`\n",
    "                 \n",
    "`xor(X)` should output `[0, 1, 1, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor(X):\n",
    "    #.........\n",
    "    return (X.sum(axis=1) == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "X = numpy.array([[0, 0],      # FALSE\n",
    "                 [0, 1],      # TRUE\n",
    "                 [1, 0],      # TRUE\n",
    "                 [1, 1]])     # FALSE\n",
    "y = xor(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2b9e099bb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.scatter(X[:,0], X[:,1], c=y, s=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "We can define a simple two layer neural network by hand which solves the XOR classification problem. The network has parameters $\\mathbf{W}$ and $\\mathbf{U}$, and computes the following:\n",
    "\n",
    "$$Y = \\sigma(U(\\sigma(WX^T))$$\n",
    "\n",
    "Where $\\mathbf{X}$ is the input array, with shape Nx2, $\\mathbf{W}$ is a 2x2 matrix, and $\\mathbf{U}$ is a 1x2 matrix. The result is a 1xN matrix (i.e. a single row vector) of XOR values.\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "Define function `sigma` which returns one if the input is greater than or equal to 0.5, and zero otherwise.\n",
    "\n",
    "Given `X = numpy.array([[0.1, 0.3], [0.5, 0.7]])`\n",
    "        \n",
    "`sigma(X)` should output \n",
    "\n",
    "`[[0. 0.]\n",
    "[1. 1.]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(X):\n",
    "    #...............\n",
    "    return (X >= 0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75361463 0.95510798]\n",
      " [0.86941517 0.4427421 ]\n",
      " [0.66778798 0.20810856]]\n",
      "[[1. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "z = numpy.random.uniform(0,1,(3,2))\n",
    "print(z)\n",
    "print(sigma(z))\n",
    "print(sigma(numpy.array([[0.1, 0.3],\n",
    "            [0.5, 0.7]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Define function `nnet` which takes the weight matrices W and U, and the input X, and returns the result Y computed according to the formula above.\n",
    "\n",
    "Given \n",
    "\n",
    "<pre>\n",
    "X = numpy.array([[0, 0],      \n",
    "                 [0, 1],      \n",
    "                 [1, 0],      \n",
    "                 [1, 1]])\n",
    " \n",
    "W = numpy.array([[1,-1],\n",
    "                 [-1,1]])\n",
    "                 \n",
    "U = numpy.array([1,1])\n",
    "</pre>\n",
    "\n",
    "`nnet(W, U, X)` should output `[0, 1, 1, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnet(W,U,X):\n",
    "    #..........................................\n",
    "    Z = sigma(numpy.dot(W,numpy.transpose(X)))\n",
    "    return sigma(numpy.dot(U,Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = numpy.array([[1,-1],\n",
    "                 [-1,1]])\n",
    "U = numpy.array([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what it outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0]\n",
      "[0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nnet(W, U, X)\n",
    "print(y)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the outputs as a function of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a grid of points for plotting\n",
    "shape=(20,20)\n",
    "grid = numpy.array([ [i,j] for i in numpy.linspace(0,1,shape[0]) \n",
    "                               for j in numpy.linspace(0,1,shape[1]) ])\n",
    "# Apply the neural net to all the points\n",
    "y_pred = nnet(W, U, grid)\n",
    "pyplot.pcolor(y_pred.reshape((20,20)))\n",
    "pyplot.colorbar()\n",
    "pyplot.xticks([])\n",
    "pyplot.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XOR NN with TensorFlow\n",
    "\n",
    "We'll now learn how to build a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "# Add two hidden layers with 4 hidden units each, and the tanh activation.\n",
    "\n",
    "model.add(Dense(4, input_dim=2, activation='tanh'))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "\n",
    "# The final layer is the output layer with an inverse logit activation function.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Use the Adam optimizer. Adam works similar to regular SGD, \n",
    "# but with some important improvements: https://arxiv.org/abs/1412.6980\n",
    "optimizer = Adam(learning_rate=0.02)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model, specifying number of epochs, size of the minibatch, and whether to print extra information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1          x2          F(x1, x2)\n",
      "[[0.         0.         0.01677552]\n",
      " [0.         1.         0.96772838]\n",
      " [1.         0.         0.98788673]\n",
      " [1.         1.         0.03300327]]\n"
     ]
    }
   ],
   "source": [
    "print(\"   x1          x2          F(x1, x2)\")\n",
    "print(np.hstack([X, model.predict(X)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the neural net to all the points\n",
    "y_pred = model.predict(grid)\n",
    "pylab.pcolor(y_pred.reshape((20,20)))\n",
    "pylab.colorbar()\n",
    "pylab.xticks([])\n",
    "pylab.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with NN on iris\n",
    "\n",
    "We will now define and train a neural network model for regression on the iris data.\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "# Inputs\n",
    "X = numpy.array(data.data[:,0:3], dtype='float32')\n",
    "# Output\n",
    "y = numpy.array(data.data[:,3], dtype='float32')\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=999)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.4\n",
    "\n",
    "\n",
    "Define a multilayer perceptron with the following specifications:\n",
    "- Hidden layer 1: size 16, activation: tanh\n",
    "- Hidden layer 2: size 16, activation: tanh\n",
    "- Output layer: size 1, activation: linear\n",
    "\n",
    "Compile it using the following specifications:\n",
    "- optimizer: Adam\n",
    "- loss: mean squared error\n",
    "\n",
    "Train the network, and try to find a good value of learning rate by monitoring the loss.\n",
    "\n",
    "Compute mean absolute error and r-squared the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..................................\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=3, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21771862\n",
      "0.8673765913370082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "y_pred = model.predict(X_val)\n",
    "print(mean_absolute_error(y_val, y_pred))\n",
    "print(r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's now do classification. The target is a categorical vector. It will need to be transformed to an array of dummies. This transform is also called one-hot encoding.\n",
    "This can be done manually, but sklearn.preprocessing has some utilities that make it simple:\n",
    "- OneHotEncoder\n",
    "- LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "X = numpy.array(data.data, dtype='float32')\n",
    "# Output\n",
    "y = numpy.array(data.target, dtype='int32')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1/3, random_state=999)\n",
    "\n",
    "# One-hot Indicator array for classes\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "onehot = LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "Y_val   = onehot.transform(y_val)\n",
    "\n",
    "print(Y_train[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.5\n",
    "\n",
    "Define a multilayer perceptron with the following specifications:\n",
    "- Hidden layer 1: size 16, activation: tanh\n",
    "- Hidden layer 2: size 16, activation: tanh\n",
    "- Output layer: size 3, activation: softmax\n",
    "\n",
    "NB: softmax is a generalization of inverse logit to more than 2 classes. It converts class scores to class probabilities, while making sure than they sum up to 1:\n",
    "\n",
    "```\n",
    "def softmax(x):\n",
    "    z = numpy.exp(x)\n",
    "    return z/numpy.sum(z)\n",
    "```\n",
    "\n",
    "Compile it using the following specifications:\n",
    "- optimizer: Adam\n",
    "- loss: categorical_crossentropy\n",
    "\n",
    "Train the network, and try to find a good value of learning rate by monitoring the loss.\n",
    "Use the method `.predict_classes` to predict the targets on validation data.\n",
    "Compute the classification accuracy on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.....................................\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(3, activation='softmax')) # We need to have as many units as classes, \n",
    "                                                             # and softmax activation\n",
    "optimizer = Adam(lr=0.001)\n",
    "# For classification, the loss function should be categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "#.....................................\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict_classes(X_val, verbose=False)\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.6\n",
    "\n",
    "\n",
    "Train a neural network classifier on the handwritten digits dataset. \n",
    "This dataset comes with scikit learn and can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "\n",
    "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
    "    pylab.subplot(2, 5, index + 1)\n",
    "    pylab.axis('off')\n",
    "    pylab.imshow(image,cmap=plt.cm.gray_r)\n",
    "    pylab.title('%i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets are in `digits.target` and the pixel values flattened into an array are in `digits.data`.\n",
    "\n",
    "Train a classifier on the first 1000 of the images, and evaluate on the rest. \n",
    "Before testing the neural network model, check the classification error rate of a logistic regression classifier as a baseline.\n",
    "\n",
    "\n",
    "Remember to convert the targets to the one-hot representation for training the neural network.\n",
    "\n",
    "Some things to try when training a neural network model for this dataset:\n",
    "\n",
    "- start with two or three hidden layers\n",
    "- use between 32 to 128 units in each layer\n",
    "- try different learning rates in the Adam optimizer (lr=0.001, lr=0.0001) and monitor the loss function\n",
    "- train for at least 100 epochs\n",
    "- try the `relu` activation function instead of `tanh`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07277289836888334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# .....................\n",
    "X_train = digits.data[:1000,:]\n",
    "y_train = digits.target[:1000]\n",
    "X_val = digits.data[1000:,:]\n",
    "y_val = digits.target[1000:]\n",
    "\n",
    "onehot = LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "Y_val   = onehot.transform(y_val)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "baseline = LogisticRegression()\n",
    "baseline.fit(X_train, y_train)\n",
    "print(1-accuracy_score(y_val, baseline.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.....................................\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax')) # We need to have as many units as classes, \n",
    "                                                             # and softmax activation\n",
    "optimizer = Adam(lr=0.0001)\n",
    "# For classification, the loss function should be categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07026348808030114\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val, verbose=0)\n",
    "print(1-accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
