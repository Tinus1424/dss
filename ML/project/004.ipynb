{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTER / LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadFile(googleTrue, file = None ):\n",
    "    if googleTrue == True:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        x = pd.read_csv(\"drive/MyDrive/train_data.csv\")\n",
    "    else:\n",
    "        x = pd.read_csv(file)\n",
    "    return x\n",
    "\n",
    "train_data = loadFile(False, \"data/train_data.csv\")\n",
    "test_data = loadFile(False, \"data/test_data.csv\")\n",
    "supp_data = loadFile(False, \"data/supplimental_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions\n",
    "Time converted to numerical because most models do not support datetime. Missing values in levelprogression were filled with 0 because most NA's also had sessionlength 0. sumDf creates summary statistics for each user which are used to train the kmeans clustering\n",
    "algorithm. In previous iterations, currentgamemode was converted to a binary with career being 1 and all other values 0, due to class imbalance that was the best. QuestionTiming was also converted to binary but these did not help much either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillLPA(df):\n",
    "    df.loc[:, \"LevelProgressionAmount\"] = df.loc[:, \"LevelProgressionAmount\"].apply(lambda x: 0 if pd.isna(x) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numericalTime(df):\n",
    "    TimeUtcDate = pd.to_datetime(df.loc[:, \"TimeUtc\"])\n",
    "    TimeUtcNumeric = pd.to_numeric(TimeUtcDate)\n",
    "    df.loc[:, \"TimeUtc\"] = TimeUtcNumeric\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binaryQuestion(df):\n",
    "    df.loc[:, \"QuestionType\"] = df.loc[:, \"QuestionType\"].astype(str)\n",
    "    df.loc[:, \"QuestionType\"] = df.loc[:, \"QuestionType\"].apply(lambda x: 1 if x.strip() == \"Wellbeing\" else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaleVariables(df):\n",
    "    scaler = StandardScaler()\n",
    "    grouped = df.groupby(\"UserID\")\n",
    "    result = pd.DataFrame()\n",
    "    for UserID, data in grouped:\n",
    "        before = pd.DataFrame(data[FEATURES])\n",
    "        after = scaler.fit_transform(X = before)\n",
    "        afterDf = pd.DataFrame(after, index=data.index, columns = FEATURES)\n",
    "        result = pd.concat([result, afterDf])\n",
    "    result = result.sort_index()\n",
    "    try:\n",
    "        df1 = df[[\"UserID\", \"QuestionType\", \"ResponseValue\"]]\n",
    "    except:\n",
    "        df1 = df[[\"UserID\", \"QuestionType\"]]\n",
    "    df2 = pd.concat([df1, result], axis = 1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped Model\n",
    "Grouping the users is a better way for going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTSELECT = [\"UserID\", \"TimeUtc\", \"CurrentSessionLength\", \"LevelProgressionAmount\", \"QuestionType\"]\n",
    "\n",
    "SELECT = [\"UserID\", \"TimeUtc\", \"CurrentSessionLength\", \"LevelProgressionAmount\", \"QuestionType\", \"ResponseValue\"]\n",
    "FEATURES =  [\"TimeUtc\", \"CurrentSessionLength\", \"LevelProgressionAmount\"]\n",
    "\n",
    "TARGET = [\"ResponseValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m GS3 \u001b[38;5;241m=\u001b[39m numericalTime(GS2)\n\u001b[0;32m      8\u001b[0m GS4 \u001b[38;5;241m=\u001b[39m binaryQuestion(GS3)\n\u001b[1;32m----> 9\u001b[0m GS0 \u001b[38;5;241m=\u001b[39m scaleVariables(GS4)\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mscaleVariables\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      7\u001b[0m     after \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X \u001b[38;5;241m=\u001b[39m before)\n\u001b[0;32m      8\u001b[0m     afterDf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(after, index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex, columns \u001b[38;5;241m=\u001b[39m FEATURES)\n\u001b[1;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([result, afterDf])\n\u001b[0;32m     10\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:671\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjs:\n\u001b[0;32m    670\u001b[0m     indexers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax, new_labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes):\n\u001b[0;32m    672\u001b[0m         \u001b[38;5;66;03m# ::-1 to convert BlockManager ax to DataFrame ax\u001b[39;00m\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis:\n\u001b[0;32m    674\u001b[0m             \u001b[38;5;66;03m# Suppress reindexing on concat axis\u001b[39;00m\n\u001b[0;32m    675\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:702\u001b[0m, in \u001b[0;36m_Concatenator.new_axes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    705\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:703\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    705\u001b[0m     ]\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:760\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevels supported only when keys is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 760\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _concat_indexes(indexes)\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _make_concat_multiindex(\n\u001b[0;32m    763\u001b[0m         indexes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    764\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:778\u001b[0m, in \u001b[0;36m_concat_indexes\u001b[1;34m(indexes)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concat_indexes\u001b[39m(indexes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m--> 778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indexes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(indexes[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5489\u001b[0m, in \u001b[0;36mIndex.append\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   5486\u001b[0m names \u001b[38;5;241m=\u001b[39m {obj\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m to_concat}\n\u001b[0;32m   5487\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m-> 5489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concat(to_concat, name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5497\u001b[0m, in \u001b[0;36mIndex._concat\u001b[1;34m(self, to_concat, name)\u001b[0m\n\u001b[0;32m   5492\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5493\u001b[0m \u001b[38;5;124;03mConcatenate multiple Index objects.\u001b[39;00m\n\u001b[0;32m   5494\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5495\u001b[0m to_concat_vals \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39m_values \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat]\n\u001b[1;32m-> 5497\u001b[0m result \u001b[38;5;241m=\u001b[39m concat_compat(to_concat_vals)\n\u001b[0;32m   5499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39m_with_infer(result, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\concat.py:78\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     77\u001b[0m     to_concat_arrs \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[np.ndarray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(to_concat_arrs, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "S = supp_data(\"data/supplimental_data.csv\")\n",
    "GS = pd.concat([G, S])\n",
    "GS = GS.reset_index()\n",
    "GS = GS.sort_values(by = [\"UserID\"])\n",
    "GS1 = GS[SELECT]\n",
    "GS2 = fillLPA(GS1)\n",
    "GS3 = numericalTime(GS2)\n",
    "GS4 = binaryQuestion(GS3)\n",
    "GS0 = scaleVariables(GS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pGrid = {\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"max_features\": [2, 10],\n",
    "    \"min_samples_split\": [10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfcvList = {}\n",
    "modelCV = {}\n",
    "grouped = GS0.groupby(\"UserID\")\n",
    "notIncluded = {}\n",
    "\n",
    "\n",
    "for UserID, data in grouped:\n",
    "    data = data.reset_index()\n",
    "    dataSize = len(data)\n",
    "    testSize = int(dataSize * 0.7)\n",
    "    if testSize < 3:\n",
    "        continue\n",
    "    train, test = data.iloc[:testSize], data.iloc[testSize:]\n",
    "    X, y = train[FEATURES], np.ravel(train[TARGET])\n",
    "    X_test, y_test = test[FEATURES], np.ravel(test[TARGET])\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits = 2)\n",
    "    rf = RandomForestRegressor(criterion = \"squared_error\")\n",
    "    rfcv = GridSearchCV(estimator = rf,\n",
    "                        cv = tscv,\n",
    "                        param_grid = pGrid,\n",
    "                        scoring='neg_mean_absolute_error',\n",
    "                        n_jobs =-1)\n",
    "    rfcv = rfcv.fit(X, y)\n",
    "    bestModel = rfcv.best_estimator_\n",
    "    bestParams = rfcv.best_score_\n",
    "    testPredict = bestModel.predict(X_test)\n",
    "    testTrue = y_test\n",
    "    testMAE = mean_absolute_error(testTrue, testPredict)\n",
    "    rfcvList[UserID] = rfcv\n",
    "    modelCV[UserID] = bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = GS0.groupby(\"UserID\")\n",
    "finalModel = {}\n",
    "for UserID, data in grouped: \n",
    "    data = data.reset_index()\n",
    "    X, y = data[FEATURES], np.ravel(data[TARGET])\n",
    "    if UserID in modelCV:\n",
    "        rf = modelCV[UserID]\n",
    "    else:\n",
    "        rf = RandomForestRegressor(max_depth = 5, max_features = 10, min_samples_split=10)\n",
    "    rf.fit(X, y)\n",
    "    finalModel[UserID] = rf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = G0[FEATURES]\n",
    "y = np.ravel(G0[TARGET])\n",
    "rf1 = RandomForestRegressor(max_depth = 5, max_features = 10, min_samples_split=10)\n",
    "rf1.fit(X,y)\n",
    "finalModel[\"NoID\"] = rf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PREDICTION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"data/test_data.csv\")\n",
    "y1 = y[TESTSELECT]\n",
    "y2 = fillLPA(y1)\n",
    "y3 = numericalTime(y2)\n",
    "y4 = binaryQuestion(y3)\n",
    "y0 = scaleVariables(y4)\n",
    "y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yGrouped = y0.groupby(\"UserID\")\n",
    "ypreds = []\n",
    "\n",
    "for UserID, data in yGrouped:\n",
    "    data = data.reset_index()\n",
    "    data = data[FEATURES]\n",
    "    if UserID in finalModel:\n",
    "        userPredictions = finalModel[UserID].predict(data)\n",
    "    else:\n",
    "        userPredictions = finalModel[\"NoID\"].predict(data)\n",
    "    ypreds.extend(userPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"predicted.csv\", ypreds)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
